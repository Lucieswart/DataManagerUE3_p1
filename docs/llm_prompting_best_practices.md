# Best Practices for LLM Prompting in Code Development

*Last updated: July 2024*

## Introduction

Large Language Models (LLMs) like ChatGPT, Claude, and Gemini have become powerful tools for coding assistance. However, the quality of output is largely dependent on the quality of input prompts. This guide outlines best practices for effectively leveraging LLMs in your coding workflow.

## Effective Prompting Strategies

### 1. Isolate Problems in Separate Conversations

**Why it matters:**
- Maintains context clarity
- Creates a clean thought trail
- Reduces confusion for both the LLM and future readers
- Makes it easier to reference specific solutions later

**Best practice:**
```
Instead of: "Now I have another issue with my code..."
Use: *Start a new chat* "I'm working on a Python function that processes spectral data..."
```

**Educational value:**
When teaching or learning programming, isolated conversations create clear reference points that show a learner's problem-solving approach and thought process. Instructors can review these conversation threads to understand where conceptual gaps might exist (and why not even questionning the llm itself about the conversation ! ).

**Pro tip:** Save or bookmark important conversations with descriptive titles for future reference.

### 2. Question and Critique LLM Responses

**Why it matters:**
- Validates your understanding
- Uncovers potential issues in LLM reasoning
- Refines solutions through iterative feedback
- Helps develop critical thinking skills

**Effective questioning approaches:**
- "Can you explain why you used this particular approach?"
- "Are there any edge cases this solution doesn't handle?"
- "What are the performance implications of this implementation?"

**Remember:** LLMs can make mistakes or present outdated information. Critical engagement improves outcomes.

### 3. Be Precise and Structured in Your Requests

**Why it matters:**
- Enables more accurate and useful responses
- Reduces iterations needed to get suitable solutions
- Creates clarity about requirements

**A well-structured coding prompt includes:**
- Function/component purpose
- Expected inputs (including types and formats)
- Expected outputs (including types and formats)
- Behavioral requirements
- Context about the larger system
- Any constraints or considerations

**Example:**
```
Poor: "Write a function to process spectral data."

Better: "I need a Python function called 'normalize_spectra' that:
- Takes a numpy array of spectral readings (shape: n_samples Ã— n_wavelengths)
- Normalizes each spectrum to a range of 0-1
- Handles outliers by capping values beyond 3 standard deviations
- Returns the normalized array with the same shape as input
- Is optimized for large datasets (potentially millions of readings)

I'm using Python 3.10 with NumPy 1.25."
```

**Pre-prompt research:** Before diving into implementation details, ask if popular packages or established patterns exist for solving your problem. This can save time and result in more robust solutions.

### 4. Encourage LLMs to Ask Clarifying Questions

**Why it matters:**
- Reveals assumptions you might have missed
- Helps refine your own understanding of the problem
- Often leads to more suitable solutions
- Creates a more interactive, collaborative experience

**Implementation:**
Explicitly invite the LLM to ask questions by including statements like:
- "Feel free to ask clarifying questions if anything is ambiguous."
- "What additional information would help you provide a better solution?"
- "Please identify any assumptions you're making based on my description."

**Example dialogue:**
```
User: "I need code to extract spectral features from my dataset."

LLM: "I'd be happy to help with that. Before I provide a solution, I have a few questions:
1. What format is your spectral data in? (CSV, specialized format, etc.)
2. What specific features are you trying to extract? (peaks, valleys, specific bands)
3. Are you working with any specific type of spectra? (Raman, NIR, hyperspectral imaging)
4. Do you have any preprocessing requirements before feature extraction?"
```

This interaction leads to a clearer understanding of requirements and typically results in more appropriate solutions.

## Advanced Strategies

### Code Review and Improvement

When you have existing code, ask the LLM to:
- Review it for potential bugs or edge cases
- Suggest optimizations for performance
- Identify better patterns or approaches
- Add proper error handling
- Improve documentation or type hints

### Test Generation

LLMs excel at generating test cases. Ask for:
- Unit tests covering edge cases
- Integration test examples
- Test fixtures and mocks
- Property-based testing approaches

### Breaking Down Complex Problems

For large tasks, use the LLM to:
1. Outline the high-level approach
2. Break the problem into smaller sub-problems
3. Create an implementation plan
4. Tackle each component individually

### Version Control Integration

**Why it matters:**
- Prevents overwhelming code changes
- Creates clear checkpoints for review
- Maintains project history and traceability
- Facilitates focused work on manageable chunks

**Introduction to Git and GitHub:**
[Git](https://git-scm.com/) is the industry-standard version control system that allows you to track changes in your code over time. When paired with [GitHub](https://github.com), a cloud-based hosting service, you gain additional collaboration features and access to AI-powered development tools.

Basic Git workflow with LLMs:
```bash
# Create a new branch for your feature
git checkout -b feature-name

# After generating and validating code with an LLM
git add <modified-files>
git commit -m "[feat] Add function to normalize spectral data"

# When ready to merge into main project
git push origin feature-name
# Then create a pull request on GitHub
```

**Best practices:**
- Work on and commit one function/component at a time
- Write meaningful commit messages that explain changes
- Commit immediately after generating satisfactory code
- Use feature branches for exploratory LLM-assisted development
- Consider using [conventional commits](https://www.conventionalcommits.org/) format for better organization

**Example workflow:**
```
1. Define a single function/component requirement
2. Prompt the LLM to generate the implementation
3. Review, test, and refine until satisfactory
4. Commit the working implementation
5. Proceed to the next function/component
```

This approach is particularly valuable when working with AI coding agents that can make multiple changes across your codebase.

**Getting Started with GitHub and GitHub Copilot:**
1. Create a free [GitHub account](https://github.com/signup) if you don't already have one
2. Install [Visual Studio Code](https://code.visualstudio.com/)
3. Set up the [GitHub Copilot extension](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot) in VS Code
4. Consider subscribing to [GitHub Copilot](https://github.com/features/copilot) to access its full features
   (There are free options for students and open source contributors)

GitHub Copilot provides real-time code suggestions as you type and can help implement entire functions based on comments or function signatures, making it an excellent companion for day-to-day coding tasks.

## Understanding AI Coding Agents vs. Conversational LLMs

### Conversational LLMs (ChatGPT, Claude, etc.)
- Interact through text-based dialogue only
- Cannot directly read or modify your files
- Require you to manually implement suggestions
- Limited context window to share code and requirements

### AI Coding Agents (Cursor, GitHub Copilot, etc.)
- Can read and understand your entire codebase
- Can autonomously modify files and generate code
- Navigate complex project structures
- Execute commands and tools on your behalf
- Continuously adapt to your project's evolving context

**Working effectively with AI coding agents:**
- Start with a clear project structure
- Give precise instructions about what you want to accomplish
- Review changes before accepting them
- Use version control diligently to track agent-made changes
- Break complex tasks into smaller, manageable pieces

## Common Pitfalls to Avoid

- **Overly vague prompts**: "Fix my code" is less helpful than "My function fails when given empty input"
- **Accepting solutions without understanding**: Always review and understand the code before implementation
- **Neglecting to specify constraints**: Memory limits, performance requirements, compatibility needs
- **Forgetting to provide context**: Related code, system architecture, or business rules
- **Ignoring code quality aspects**: Security, maintainability, and readability still matter

## Conclusion

Effective LLM prompting is an evolving skill that improves with practice. By isolating problems, questioning responses, providing precise specifications, and encouraging clarification, you can dramatically improve the quality and relevance of LLM-assisted code development.

Remember that LLMs are tools to augment your abilities, not replace good coding practices or deep understanding of your problem domain. The most effective use comes from collaborative iteration and maintaining critical thinking throughout the process.

---

*This guide will be updated periodically as LLM capabilities and best practices evolve.* 